# -*- coding: utf-8 -*-
"""Amazon_review.ipynb

Automatically generated by Colaboratory.


Original file is located at
    https://colab.research.google.com/drive/1aKD2rMvAa4B7KesyMi6Oxwla4Es23cte

# **Amazon product Review Analysis**

### 1 Web scraping product review
"""


from bs4 import BeautifulSoup
import requests

import pandas as pd
from dateutil.parser import parse

from flask import Flask,render_template,url_for,request

import pickle
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.externals import joblib

app = Flask(__name__)

@app.route('/')
def home():
	return render_template('home.html')




def getReview_link(s,u):
  if s !="stop":
    soup= BeautifulSoup(page.content, 'html.parser')
    rev=soup.find('div',id="reviews-medley-footer")
    t=rev.find('a').get('href')
    r_u="https://www.amazon.in"+t+"&sortBy=recent"
    return r_u

def getReviews(url,pg):
 
  ur=url+"&pageNumber="+str(pg)+"&sortBy=recent"
  page = requests.get(ur,cookies=cookie,headers=header)
  r_h=[]
  r_b=[]
  r_t=[]
 
  if page.status_code==200:
    soup= BeautifulSoup(page.content, 'html.parser')
    r=soup.find('div',id="cm_cr-review_list")
    
    if r =="f":
       return r_h,r_b,r_t,pg
    else:
 
      ty=soup.find('div',class_="a-section a-spacing-none review-views celwidget")
      
      rt=ty.find_all("a",{'data-hook':"review-title"})
      
      for i in rt:
          if i is None:
            r_h.append(None)
          else:
            v=i.get_text()
            v=v.strip("\n")
            
            r_h.append(v)      
      rb=soup.find_all("span",{'data-hook':"review-body"})
      for i in rb:
        if i is None:
          r_b.append(None)
        else:
          v=i.get_text()
          v=v.strip("\n")
          r_b.append(v)
      rti=soup.find_all("span",{'data-hook':"review-date"})
      for i in rti:
        if i is None:
          r_t.append(None)
        else:
          
          t=i.get_text()
          date=parse(t,fuzzy=True,dayfirst=True)
          r_t.append(date)
      
      nextp=soup.find("ul",class_="a-pagination")
      npg=0
      if (nextp.find("li",class_="a-disabled a-last")) is not None:
        return r_h,r_b,r_t,npg
      elif (nextp.find("li",class_="a-last")) is not None:
          
          npg=pg+1
          return r_h,r_b,r_t,npg

@app.route('/Review_extract',methods=['POST'])
def Review_extract
	if request.method == 'POST':
		message = request.form['message']
		p = [message]
		
	cookie={}
	header={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'}

	Reviews=pd.DataFrame()
	page = requests.get(p,cookies=cookie,headers=header)
	if page.status_code==200:
   		st= page
	else:
   		st="stop"
	H=[]
	B=[]
	D=[]
	rev_link=getReview_link(st,p)

	pg=1
	ntpg=1
	while (pg>=ntpg):
   		print(pg)
   		r_t=[]
   		r_h=[]
   		r_b=[]
   		r_h,r_b,r_t,ntpg=getReviews(rev_link,pg)
   
   		H.extend(r_h)
   		B.extend(r_b)
   		D.extend(r_t)
   		if ntpg>pg:
      			pg=ntpg
      			continue
   		else:
      			break
	Reviews=pd.DataFrame(({"Review_title":H,
         "Review_body":B,
         "Review_date":D}))
	no_reviews=length(H)
	return render_template('result.html',prediction = no_reviews)

if __name__ == '__main__':
	app.run(debug=True)




